{
  "cells": [
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "R3qmOgZijxBQ"
      },
      "source": [
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/tuankhoin/COMP30027-Practical-Solutions/blob/main/2022/Week%211.ipynb)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yWYnJAzLjwp6",
        "outputId": "5f415aec-adf1-4db5-ea9b-f08535c81d4f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive \n",
        "drive.mount('/content/gdrive')\n",
        "path = \"gdrive/My Drive/COMP30027 (T)/W11/\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I-VbSn_jjmAB"
      },
      "source": [
        "######  The University of Melbourne, School of Computing and Information Systems\n",
        "# COMP30027 Machine Learning, 2022 Semester 1\n",
        "\n",
        "## Week 11 - Neural Networks\n",
        "\n",
        "Why you may want to attend:\n",
        "- The reason 69% of the students enrolled in this subject 👌\n",
        "- Some cool terminology that you can use to flex today:\n",
        "  - Multi-Layer Perceptron\n",
        "  - Standardization\n",
        "  - Pipeline\n",
        "  - Hyperparameter Tuning with Grid Search\n",
        "- It is examinable (oh no!)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ItiotL4TjmAF"
      },
      "source": [
        "### NOTE:  You will need the newer (18.1) build of `scikit-learn` for its neural network support."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4CIhFNiRjmAG"
      },
      "source": [
        "\n",
        "### Exercise 1.\n",
        "The Multilayer Perceptron is available from (newer builds of) `scikit-learn` as `sklearn.neural_network.MLPClassifier`.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xlE4EvTbjmAH"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from sklearn import datasets\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from collections import Counter"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "653kbGuDjmAI"
      },
      "source": [
        "### Exercise 1.(a) \n",
        "Build a default Multilayer Perceptron to classify the `Iris` data. Evaluate its cross-validation accuracy."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iP786iIwjmAJ",
        "outputId": "7ccb7066-1802-4f7a-ed4f-89fdccaf409d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "X: (150, 4) y: {0, 1, 2}\n",
            "corss-val acc: 0.9800000000000001\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "MLPClassifier(max_iter=2000)"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "iris = datasets.load_iris()\n",
        "X = iris.data\n",
        "y = iris.target\n",
        "print('X:', X.shape, 'y:', set(y))\n",
        "\n",
        "\n",
        "clf = MLPClassifier(max_iter=2000)\n",
        "\n",
        "print('corss-val acc:', np.mean(cross_val_score(clf, X, y, cv=5)))\n",
        "clf.fit(X, y)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hPZ0KDizjmAL"
      },
      "source": [
        "### Exercise 1.(b) \n",
        "Check the `coefs_` and `n_layers_` attributes of the fitted classifier to examine the resulting neural network."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "grhpDsnujmAM",
        "outputId": "af0cf138-18da-4766-dfa5-86d9f9dc9d10"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "parameter shapes: [(4, 100), (100, 3)]\n",
            "num layers: 3\n"
          ]
        }
      ],
      "source": [
        "#print(clf.coefs_)\n",
        "print('parameter shapes:',[p.shape for p in clf.coefs_])\n",
        "print('num layers:', clf.n_layers_)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "44BVZ2q1jmAN"
      },
      "source": [
        "### Exercise 2.\n",
        "One important issue with this Multilayer Perceptron is that it is sensitive to the scale of the input attribute values.\n",
        "### Exercise 2.(a) Standardization\n",
        "Read up on the `StandardScaler` , and re-scale the `Iris` data so that each attribute has a *mean* of 0 and a *variance* of 1. Evaluate and examine the resulting neural network built on the re-scaled data.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "irISJeVJjmAO",
        "outputId": "4681fb77-f0c8-4030-b381-c622a9494795"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Cross-val cheating standardised features acc: 0.9666666666666668\n"
          ]
        }
      ],
      "source": [
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "scaler = StandardScaler()\n",
        "clf = MLPClassifier(max_iter=2000)\n",
        "#it is cheating because the mean and variance are estimated using both training and test data\n",
        "print('Cross-val cheating standardised features acc:', np.mean(cross_val_score(clf, scaler.fit_transform(X), y, cv=5))) \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mAmF4-_v2V4D"
      },
      "source": [
        "Why is it not good?\n",
        "\n",
        "*Because by scaling the whole dataset, you would have put a bit of test info to the training process. It's like peeping a few card in the deck.*\n",
        "\n",
        "- Solution? Just do it after splitting!\n",
        "- ToO mAny sTEpS? Here comes Pipeline Perri!\n",
        "\n",
        "<details>\n",
        "<summary>Pipeline Perri can fit multiple models at once.</summary>\n",
        "<s>Just like their cousin Piper Perri.</s>\n",
        "</details>\n",
        "\n",
        "> The Pipeline is built using a list of `(key, value)` pairs, where the key is a string containing the name you want to give this step and value is an estimator object:\n",
        "```python\n",
        "from sklearn.pipeline import Pipeline\n",
        "estimators = [('reduce_dim', PCA()), ('clf', SVC())]\n",
        "pipe = Pipeline(estimators)\n",
        "```\n",
        "If you don't need to name them:\n",
        "```python\n",
        "from sklearn.pipeline import make_pipeline\n",
        "make_pipeline(Binarizer(), MultinomialNB())\n",
        "```\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qf2LM9ZOjmAP"
      },
      "source": [
        "### Exercise 2.(c) \n",
        "(Harder) Calculating the _mean_ and _variance_ on the entire data set (before splitting into train/test sets) is cheating slightly. Write a re-scale function that calculates the scaling factors for the training data, and applies the scaler to the test data. Then, write a wrapper function that uses this to cross-validate.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t3yFK-tOjmAP",
        "outputId": "87b3fb06-d681-4da8-babe-f5e0c04e0edc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Cross-val noncheating standardised features acc: 0.9666666666666668\n"
          ]
        }
      ],
      "source": [
        "clf = MLPClassifier(max_iter=2000)\n",
        "#this way we don't cheat. Read more on pipelines https://scikit-learn.org/stable/modules/compose.html\n",
        "pipeline = Pipeline([('transformer', scaler), ('estimator', clf)])\n",
        "print('Cross-val noncheating standardised features acc:', np.mean(cross_val_score(pipeline, X, y, cv=5)))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ofOrQe3LjmAQ"
      },
      "source": [
        "*You might not see reduction in performance for the noncheating method, but in general it is best to standardise only the training data (`fit_transform`), and then apply the transformation to the test data (`transform`).*\n",
        "\n",
        "*Also you didn't see improvements with standardisation, which might be the result of the neural network not being tuned well in terms of regularisation, and number/size of the layers.*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bho9zgX9jmAQ"
      },
      "source": [
        "### Exercise 3 \n",
        "You can coerce the Multilayer Perceptron to have specifically–sized hidden layers using the `hidden_layer_sizes` parameter.\n",
        "### Exercise 3.(a) \n",
        "Train a Multilayer Perceptron on the two-class `Abalone` data, and examine the resulting neural\n",
        "network.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oO0mGbORjmAR",
        "outputId": "fb1405f4-2270-487d-e2ab-fd0c17c19b45"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "X: (4177, 7) y: {0, 1}\n",
            "[(7, 100), (100, 1)]\n"
          ]
        }
      ],
      "source": [
        "def convert_class(raw, num_class=2):\n",
        "    raw = int(raw)\n",
        "    if num_class == 2:\n",
        "        return 0 if raw<=10 else 1\n",
        "    elif num_class == 3:\n",
        "        return 0 if raw<=8 else 1 if 9<=raw<=10 else 2\n",
        "    elif num_class == 29:\n",
        "        return raw\n",
        "\n",
        "def load_abalone(addsex=False, num_class=2, path=''):\n",
        "    X, y = [], []\n",
        "    with open(path + 'abalone.data', 'r') as fin:\n",
        "        for line in fin:\n",
        "            atts = line[:-1].split(\",\")\n",
        "            if not addsex:\n",
        "                X.append(atts[1:-1])\n",
        "            else:\n",
        "                sex = atts[0]\n",
        "                if sex == \"M\": sex = 0\n",
        "                elif sex==\"I\": sex = 1\n",
        "                elif sex==\"F\": sex = 2\n",
        "                else: sex = 3\n",
        "                \n",
        "                X.append([sex] + atts[1:-1])\n",
        "            y.append(convert_class(atts[-1], num_class))\n",
        "    X = np.array(X, dtype=float)\n",
        "    return X, y\n",
        "\n",
        "# Remove 'path' argument if you are running the Notebook locally\n",
        "X, y = load_abalone(addsex=False, num_class=2, path=path)\n",
        "print('X:', X.shape, 'y:', set(y))\n",
        "\n",
        "clf = MLPClassifier(max_iter=2000)\n",
        "clf.fit(X,y)\n",
        "print([p.shape for p in clf.coefs_])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F1azAKEXjmAR"
      },
      "source": [
        "### Exercise 3.(b) \n",
        "(Harder) Change the size and/or number of hidden layers. How are the resulting weights affected? Can you discern any relationship between the weights for layers of varying sizes?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nUO0oy2IjmAS",
        "outputId": "b44574b8-ff80-4602-a257-56ccad7e257d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[(7, 10), (10, 10), (10, 4), (4, 1)]\n"
          ]
        }
      ],
      "source": [
        "clf = MLPClassifier(hidden_layer_sizes=[10, 10, 4], max_iter=2000)\n",
        "clf.fit(X, y)\n",
        "print([p.shape for p in clf.coefs_])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LMNCx90wjmAS"
      },
      "source": [
        "### Exercise 4. \n",
        "There are a couple of different tune-able parameters for the MLPClassifier , mostly dealing with the weight optimisation — however, it is often worthwhile to tune the Regularisation parameter (α).\n",
        "### Exercise 4.(a) \n",
        "Try varying orders of α between 10 and 10e−5 for a Multilayer Perceptron built on the two-class `Abalone` data. How much variance in cross-validation accuracy do you observe?\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h3SzWEgXjmAS",
        "outputId": "6202a5ef-8f2a-45e3-eb04-a1fd82ac891c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[1e-07, 1e-06, 1e-05, 0.0001, 0.001, 0.01, 0.1, 1.0, 10.0]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 11%|█         | 1/9 [00:14<01:59, 14.93s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "alpha: 1e-7\t mean_acc: 0.79004\t standard_dev_acc: 0.01472\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 22%|██▏       | 2/9 [00:27<01:34, 13.57s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "alpha: 1e-6\t mean_acc: 0.78573\t standard_dev_acc: 0.01284\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 33%|███▎      | 3/9 [00:41<01:21, 13.62s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "alpha: 1e-5\t mean_acc: 0.78812\t standard_dev_acc: 0.01383\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 44%|████▍     | 4/9 [00:55<01:09, 13.81s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "alpha: 1e-4\t mean_acc: 0.78549\t standard_dev_acc: 0.01013\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 56%|█████▌    | 5/9 [01:09<00:55, 13.89s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "alpha: 1e-3\t mean_acc: 0.79004\t standard_dev_acc: 0.01322\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 67%|██████▋   | 6/9 [01:25<00:43, 14.55s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "alpha: 1e-2\t mean_acc: 0.78525\t standard_dev_acc: 0.01331\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 78%|███████▊  | 7/9 [01:36<00:27, 13.52s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "alpha: 1e-1\t mean_acc: 0.78477\t standard_dev_acc: 0.01495\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 89%|████████▉ | 8/9 [01:42<00:11, 11.19s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "alpha: 1e0\t mean_acc: 0.77879\t standard_dev_acc: 0.02362\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 9/9 [01:46<00:00, 11.86s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "alpha: 1e1\t mean_acc: 0.74240\t standard_dev_acc: 0.03103\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "import tqdm\n",
        "alphas = [np.power(10.0, i) for i in range(-7, 2)]\n",
        "print(alphas)\n",
        "\n",
        "for alpha in tqdm.tqdm(alphas, position=0, leave=True):\n",
        "    clf = MLPClassifier(max_iter=2000, alpha=alpha)\n",
        "    pipeline = Pipeline([('transformer', scaler), ('estimator', clf)])\n",
        "    scores = cross_val_score(pipeline, X, y, cv=5, n_jobs=-1)\n",
        "    print(f'\\nalpha: 1e{np.log10(alpha):.0f}\\t mean_acc: {np.mean(scores):.5f}\\t standard_dev_acc: {np.std(scores):.5f}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iJ-HA4-4jmAT"
      },
      "source": [
        "### Exercise 4.(b) Hyperparameter Tuning with Grid Search\n",
        "Read up on the `GridSearchCV` utility, to help you in tuning the performance of the *Multilayer Perceptron*. Split the data into a training–and–tuning partition, and a test partition. What is the value of the regularisation parameter that `GridSearchCV` comes up with? How does the test accuracy compare to the default (un-tuned) `MLPClassifier` ?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EwcuJIl7jmAT",
        "outputId": "0d56b12a-dde4-4762-c770-cba7db20500c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "MLP acc without tuning: 0.7799043062200957\n",
            "Fitting 3 folds for each of 18 candidates, totalling 54 fits\n",
            "best_params {'alpha': 0.01, 'hidden_layer_sizes': [100]}\n",
            "acc with best params: 0.7811004784688995\n"
          ]
        }
      ],
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_devtest, y_train, y_devtest = train_test_split(X, y, test_size=0.4, random_state=42)\n",
        "X_dev, X_test, y_dev, y_test = train_test_split(X_devtest, y_devtest, test_size=0.5, random_state=42)\n",
        "\n",
        "clf.fit(X_train, y_train)\n",
        "print('MLP acc without tuning:', clf.score(X_test, y_test))\n",
        "\n",
        "hidden_sizes = [[100], [10, 10]]\n",
        "#arguments of MLPClassifier and a list of values for them to search and find the best.\n",
        "param_grid = {'alpha': alphas, 'hidden_layer_sizes':hidden_sizes}\n",
        "\n",
        "\n",
        "gs = GridSearchCV(estimator=clf,\n",
        "                  param_grid=param_grid,\n",
        "                  scoring='accuracy',\n",
        "                  cv=3,\n",
        "                  n_jobs=1, # Somehow verbose will not print if you do multithread\n",
        "                  verbose=1 # More verbose = More detailed print\n",
        "                  )\n",
        "\n",
        "gs.fit(X_train, y_train)\n",
        "best_params = gs.best_params_\n",
        "print('best_params', best_params)\n",
        "\n",
        "clf = MLPClassifier(max_iter=2000, **best_params)\n",
        "clf.fit(X_train, y_train)\n",
        "print('acc with best params:', clf.score(X_test, y_test))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 302
        },
        "id": "pk_dqbpEaRR6",
        "outputId": "3143927d-afeb-419d-d2dc-72d3c18333fa"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-c037bd1d-6fe7-49b6-90a1-74d4f54f39ff\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>10</th>\n",
              "      <th>11</th>\n",
              "      <th>12</th>\n",
              "      <th>13</th>\n",
              "      <th>14</th>\n",
              "      <th>15</th>\n",
              "      <th>16</th>\n",
              "      <th>17</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>alpha</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000001</td>\n",
              "      <td>0.000001</td>\n",
              "      <td>0.00001</td>\n",
              "      <td>0.00001</td>\n",
              "      <td>0.0001</td>\n",
              "      <td>0.0001</td>\n",
              "      <td>0.001</td>\n",
              "      <td>0.001</td>\n",
              "      <td>0.01</td>\n",
              "      <td>0.01</td>\n",
              "      <td>0.1</td>\n",
              "      <td>0.1</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>10.0</td>\n",
              "      <td>10.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Hidden layer size</th>\n",
              "      <td>[100]</td>\n",
              "      <td>[10, 10]</td>\n",
              "      <td>[100]</td>\n",
              "      <td>[10, 10]</td>\n",
              "      <td>[100]</td>\n",
              "      <td>[10, 10]</td>\n",
              "      <td>[100]</td>\n",
              "      <td>[10, 10]</td>\n",
              "      <td>[100]</td>\n",
              "      <td>[10, 10]</td>\n",
              "      <td>[100]</td>\n",
              "      <td>[10, 10]</td>\n",
              "      <td>[100]</td>\n",
              "      <td>[10, 10]</td>\n",
              "      <td>[100]</td>\n",
              "      <td>[10, 10]</td>\n",
              "      <td>[100]</td>\n",
              "      <td>[10, 10]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Mean test score</th>\n",
              "      <td>0.786515</td>\n",
              "      <td>0.781729</td>\n",
              "      <td>0.779338</td>\n",
              "      <td>0.785317</td>\n",
              "      <td>0.787311</td>\n",
              "      <td>0.788511</td>\n",
              "      <td>0.784126</td>\n",
              "      <td>0.780933</td>\n",
              "      <td>0.78851</td>\n",
              "      <td>0.778537</td>\n",
              "      <td>0.789309</td>\n",
              "      <td>0.781731</td>\n",
              "      <td>0.779336</td>\n",
              "      <td>0.781332</td>\n",
              "      <td>0.752591</td>\n",
              "      <td>0.772149</td>\n",
              "      <td>0.687548</td>\n",
              "      <td>0.653236</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Mean fit time</th>\n",
              "      <td>2.616513</td>\n",
              "      <td>1.252661</td>\n",
              "      <td>2.536339</td>\n",
              "      <td>1.676932</td>\n",
              "      <td>2.851301</td>\n",
              "      <td>1.756532</td>\n",
              "      <td>2.420419</td>\n",
              "      <td>1.330499</td>\n",
              "      <td>3.681538</td>\n",
              "      <td>1.454044</td>\n",
              "      <td>2.741483</td>\n",
              "      <td>1.790358</td>\n",
              "      <td>1.936064</td>\n",
              "      <td>1.313662</td>\n",
              "      <td>1.630248</td>\n",
              "      <td>1.359696</td>\n",
              "      <td>0.780962</td>\n",
              "      <td>0.657655</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Ranking</th>\n",
              "      <td>5</td>\n",
              "      <td>9</td>\n",
              "      <td>12</td>\n",
              "      <td>6</td>\n",
              "      <td>4</td>\n",
              "      <td>2</td>\n",
              "      <td>7</td>\n",
              "      <td>11</td>\n",
              "      <td>3</td>\n",
              "      <td>14</td>\n",
              "      <td>1</td>\n",
              "      <td>8</td>\n",
              "      <td>13</td>\n",
              "      <td>10</td>\n",
              "      <td>16</td>\n",
              "      <td>15</td>\n",
              "      <td>17</td>\n",
              "      <td>18</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-c037bd1d-6fe7-49b6-90a1-74d4f54f39ff')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-c037bd1d-6fe7-49b6-90a1-74d4f54f39ff button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-c037bd1d-6fe7-49b6-90a1-74d4f54f39ff');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "                         0         1         2         3         4         5   \\\n",
              "alpha                   0.0       0.0  0.000001  0.000001   0.00001   0.00001   \n",
              "Hidden layer size     [100]  [10, 10]     [100]  [10, 10]     [100]  [10, 10]   \n",
              "Mean test score    0.786515  0.781729  0.779338  0.785317  0.787311  0.788511   \n",
              "Mean fit time      2.616513  1.252661  2.536339  1.676932  2.851301  1.756532   \n",
              "Ranking                   5         9        12         6         4         2   \n",
              "\n",
              "                         6         7         8         9         10        11  \\\n",
              "alpha                0.0001    0.0001     0.001     0.001      0.01      0.01   \n",
              "Hidden layer size     [100]  [10, 10]     [100]  [10, 10]     [100]  [10, 10]   \n",
              "Mean test score    0.784126  0.780933   0.78851  0.778537  0.789309  0.781731   \n",
              "Mean fit time      2.420419  1.330499  3.681538  1.454044  2.741483  1.790358   \n",
              "Ranking                   7        11         3        14         1         8   \n",
              "\n",
              "                         12        13        14        15        16        17  \n",
              "alpha                   0.1       0.1       1.0       1.0      10.0      10.0  \n",
              "Hidden layer size     [100]  [10, 10]     [100]  [10, 10]     [100]  [10, 10]  \n",
              "Mean test score    0.779336  0.781332  0.752591  0.772149  0.687548  0.653236  \n",
              "Mean fit time      1.936064  1.313662  1.630248  1.359696  0.780962  0.657655  \n",
              "Ranking                  13        10        16        15        17        18  "
            ]
          },
          "execution_count": 46,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import pandas as pd\n",
        "pd.DataFrame([gs.cv_results_['param_alpha'],\n",
        "              gs.cv_results_['param_hidden_layer_sizes'],\n",
        "              gs.cv_results_['mean_test_score'],\n",
        "              gs.cv_results_['mean_fit_time'],\n",
        "              gs.cv_results_['rank_test_score']], \n",
        "             index=['alpha','Hidden layer size','Mean test score', 'Mean fit time', 'Ranking'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JsmLr93sZw7G",
        "outputId": "5f105ee2-2bd9-488f-d967-a7644bd91c57"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "mean_fit_time\n",
            "std_fit_time\n",
            "mean_score_time\n",
            "std_score_time\n",
            "param_alpha\n",
            "param_hidden_layer_sizes\n",
            "params\n",
            "split0_test_score\n",
            "split1_test_score\n",
            "split2_test_score\n",
            "mean_test_score\n",
            "std_test_score\n",
            "rank_test_score\n"
          ]
        }
      ],
      "source": [
        "# What more can I add?\n",
        "print('\\n'.join(gs.cv_results_.keys()))"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "prac-solns-11-2022.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}

{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tuankhoin/COMP30027-Practical-Solutions/blob/main/COMP90049/Week%208.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I-VbSn_jjmAB"
      },
      "source": [
        "######  The University of Melbourne, School of Computing and Information Systems\n",
        "# COMP90049 Intro to Machine Learning\n",
        "\n",
        "## Week 8 - Neural Networks (again!)\n",
        "- More perceptron\n",
        "- Backpropagation:\n",
        "  - The hardest bit to understand in deep learning (too many math steps)\n",
        "  - Implement library == virgin. Code by hand == chad. How about we do the maths ourselves?\n",
        "  - The moment you can distinguish yourself from the AI startup founders (who called ML, AI - boooo). T-pose time!\n",
        "- Maths! Maths! Maths!\n",
        "\n",
        "---\n",
        "## Assignment 2 & Report\n",
        "\n",
        "- Please make sure to read the questions closely:\n",
        "  - Common problem: Ask about ethic/unfairness, mentioned model performance instead.\n",
        "  - Another common problem: Ask what is ethical in the dataset, ended up complaining about that 1 feature.\n",
        "- Currently: If i can dig up the right idea from the mess, you can still grab points.\n",
        "- That's not gonna happen in the report:\n",
        "  - No right or wrong\n",
        "  - Just your resoning\n",
        "  - Anything, as long as it got proper reasoning (relating to your knowledge)\n",
        "  - Evidence, proof, EDA, etc. gimme all!\n",
        "\n",
        "Tips:\n",
        "- See if your friend can understand what you have written\n",
        "- ChatGPT can help to expand ideas, but not writing for you (even without ZeroGPT it's retarded, trust me)\n",
        "___\n",
        "\n",
        "# Theoretical questions\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1.\n",
        "> Consider the two layers deep network illustrated below. It is composed of three perceptrons. The two perceptrons of the first layer implement the AND and OR function, respectively.\n",
        "\n",
        "[![](https://mermaid.ink/img/pako:eNp1kN1qwkAQhV9lmastGKhe5qKgJi2F_oBeur0Ys2OzNNmVzS4qMU_j-_hM3ZjUINi5mjnfOQycGjIjCWLYFGaX5Wgde1sIzcJUfv1tcZuz16LwlbPolNEdkspS1p5XcztTzqLxA4uip-Pu8chmq_Ppa6CzFrB5fWgGLeHTj6RPjENiICn_XPRgcgOe-b77kQzaC99P_tXSO9leIy1hBCXZEpUMHdStLMDlVJKAOKwS7Y8AoZvg81uJjlKpnLEQb7CoaATonVkedAaxs57-TInCUF15ddEl9N41fSm8-QWk4mqT?type=png)](https://mermaid.live/edit#pako:eNp1kN1qwkAQhV9lmastGKhe5qKgJi2F_oBeur0Ys2OzNNmVzS4qMU_j-_hM3ZjUINi5mjnfOQycGjIjCWLYFGaX5Wgde1sIzcJUfv1tcZuz16LwlbPolNEdkspS1p5XcztTzqLxA4uip-Pu8chmq_Ppa6CzFrB5fWgGLeHTj6RPjENiICn_XPRgcgOe-b77kQzaC99P_tXSO9leIy1hBCXZEpUMHdStLMDlVJKAOKwS7Y8AoZvg81uJjlKpnLEQb7CoaATonVkedAaxs57-TInCUF15ddEl9N41fSm8-QWk4mqT)\n",
        "\n",
        "> Determine the weights w1, w2 and bias w0 such that the network implements the XOR function. The initial weights are set to zero, i.e., w0 = w1 = w2 = 0, and the learning rate ùúÜ (lambda) is set to 0.1.\n",
        "\n",
        "There are 2 ways of understanding this question\n",
        "### Implement `Pred(x1,x2) = (x1 & x2) ^ (x1 | x2)`\n",
        "\n",
        "x1|x2|(x1 & x2) XOR (x1 \\| x2)\n",
        "---|---|---\n",
        "1|0|1\n",
        "0|1|1\n",
        "1|1|0\n",
        "0|0|0\n",
        "\n",
        "Epoch 1:\n",
        "\n",
        "x1|x2|z = w.X|$\\hat{y}$=f(z)|y|Weight update\n",
        "---|---|---|---|---|---\n",
        "1|0|0 x (-1) + 0 x 1 + 0 x 0 = 0|0|1| (0, 0, 0) + 0.1 x (1-0) x (-1, 1, 0) = (-0.1, 0.1, 0)\n",
        "0|1|(-0.1) x -1 + 0.1 x 0 + 0 x 1 = 0.1 | 1 | 1 | No\n",
        "1|1|(-0.1) x -1 + 0.1 x 1 + 0 x 1 = 0.1 | 1 | 0 | (-0.1, 0.1, 0) + 0.1 x (0-1) x (-1, 1,1) = (0, 0, -0.1)\n",
        "0|0|0 x -1 + (-0.1) x 0 + 0 x 0 = 0 | 0|0|No\n",
        "\n",
        "Epoch 2,3,4 (sorry I'm lazy üòÅ): Try it yourself!\n",
        "\n",
        "### Implement `Pred(x1 & x2, x1 | x2) = x1 ^ x2`\n",
        "\n",
        "x1 & x2|x1 \\| x2|x1 XOR x2\n",
        "---|---|---\n",
        "0|1|1\n",
        "0|1|1\n",
        "1|1|0\n",
        "0|0|0\n",
        "\n",
        "Epoch 1:\n",
        "\n",
        "x1 & x2|x1 \\| x2|z = w.X|$\\hat{y}$=f(z)|y|Weight update\n",
        "---|---|---|---|---|---\n",
        "0|1|0 x (-1) + 0 x 0 + 0 x 1 = 0|0|1| (0, 0, 0) + 0.1 x (1-0) x (-1, 0, 1) = (-0.1, 0, 0.1)\n",
        "0|1|(-0.1) x -1 + 0 x 0 + 0.1 x 1 = 0.2 | 1 | 1 | No\n",
        "1|1|(-0.1) x -1 + 0 x 1 + 0.1 x 1 = 0.2 | 1 | 0 | (-0.1, 0, 0.1) + 0.1 x (0-1) x (-1, 1,1) = (0, -0.1, 0)\n",
        "0|0|0 x -1 + 0 x 0 + (-0.1) x 0 = 0 | 0|0|No\n",
        "\n",
        "See solution for the rest of the epochs.\n",
        "\n",
        "Question: if epoch 4 has no updates for all instance, how would epoch 5 look like?"
      ],
      "metadata": {
        "id": "fk4YOCM_ZzeD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2.\n",
        "[![](https://mermaid.ink/img/pako:eNp1kstqwzAQRX9lmJUDMdRehGJoF6nTBzQU0k2h6kKxJrGoXyhyYpNk1U_p_7S_VMmJY6elWgndc65lNFuMckEY4CLJN1HMlYbHGcvArFU5XypexMBwWiZaugmvSUFBKqJCqzwDZyN1DEu5pgzWPClpNWB4kIVUFGlpoLbOrjG47jXcvNZwBZUHL08zqPy3Lu929w5D12M4sMZuc-Ebw_V2MOkhx8gzkb-DsEsefsnWNcS4I0JDcCt-fzhfn4MTao9GhjRx3U87c2JN_6_ZXHB09pFbp_La3mNx75J3TuW3rneU_4mb7suzn-9327hLKRM4xJRUyqUwD7u1xwx1TCkxDMxWcPVu32lvuLIQXNNESJ0rDBY8WdEQeanz5zqLMNCqpBYKJTfzkJ4oaqTpYXyaKdr_ADn4olY?type=png)](https://mermaid.live/edit#pako:eNp1kstqwzAQRX9lmJUDMdRehGJoF6nTBzQU0k2h6kKxJrGoXyhyYpNk1U_p_7S_VMmJY6elWgndc65lNFuMckEY4CLJN1HMlYbHGcvArFU5XypexMBwWiZaugmvSUFBKqJCqzwDZyN1DEu5pgzWPClpNWB4kIVUFGlpoLbOrjG47jXcvNZwBZUHL08zqPy3Lu929w5D12M4sMZuc-Ebw_V2MOkhx8gzkb-DsEsefsnWNcS4I0JDcCt-fzhfn4MTao9GhjRx3U87c2JN_6_ZXHB09pFbp_La3mNx75J3TuW3rneU_4mb7suzn-9327hLKRM4xJRUyqUwD7u1xwx1TCkxDMxWcPVu32lvuLIQXNNESJ0rDBY8WdEQeanz5zqLMNCqpBYKJTfzkJ4oaqTpYXyaKdr_ADn4olY)\n",
        "\n",
        "Perform 1 epoch of backpropagation with the following information:\n",
        "- Sigmoid activation: $\\sigma(x) = \\frac{1}{1+e^{-x}}$\n",
        "- Bias is -1 instead of 1\n",
        "- Learning rate $\\alpha = 0.7$\n",
        "- Variable convention: $\\delta^{(layer)}_\\text{input neuron}$\n",
        "- Anything smaller than 1e-4 is rounded to 0.\n",
        "\n",
        "### Step 0: Start with the first instance\n",
        "Let's pick instance (1,0)\n",
        "\n",
        "### Step 1: Compute neurons\n",
        "- $a_1 = \\sigma(\\underbrace{w_{01}x_0+w_{11}x_1+w_{21}x_2}_{z_1}) = \\sigma(-2+6x_1-6x_2)$\n",
        "- $a_2 = \\sigma(z_2) = \\sigma(1+8x_1-8x_2)$\n",
        "- $y = \\sigma(2+6a_1-6a_2)$\n",
        "\n",
        "### Step 2: Compute error: $E = \\frac{1}{2}(y-\\hat{y})^2$\n",
        "\n",
        "[![](https://mermaid.ink/img/pako:eNp1kc1Kw0AUhV_lclcpNGCyDOgiJv6ARagbwXExZm5NMJkJ0wlNaLryUXwffSUnrflTvKvLOd-5zHD2mChBGOAmV7sk5drA3ZpJsLOtXl41L1NYVbnJ3Jw3pKEknVBptJInSGSaEpMpOcS6CcF1L-DyqYFzqD14vF9D7T-P_rjdOAxdj-GiS7S7M7-FeOL-qF4L0aje_sq0EI5mZM2vd-fzYzEANh1O1RGO_8L-7NqVU3v9lfkjrp3a7yP_O_PvTK-NDkmBSyxIFzwTtol9JzM0KRXEMLCr4PqNIZMHy1Wl4IZikRmlMdjwfEtL5JVRD41MMDC6oh6KMm4LLAaKjqHVqe9j7Ydvs22QDA?type=png)](https://mermaid.live/edit#pako:eNp1kc1Kw0AUhV_lclcpNGCyDOgiJv6ARagbwXExZm5NMJkJ0wlNaLryUXwffSUnrflTvKvLOd-5zHD2mChBGOAmV7sk5drA3ZpJsLOtXl41L1NYVbnJ3Jw3pKEknVBptJInSGSaEpMpOcS6CcF1L-DyqYFzqD14vF9D7T-P_rjdOAxdj-GiS7S7M7-FeOL-qF4L0aje_sq0EI5mZM2vd-fzYzEANh1O1RGO_8L-7NqVU3v9lfkjrp3a7yP_O_PvTK-NDkmBSyxIFzwTtol9JzM0KRXEMLCr4PqNIZMHy1Wl4IZikRmlMdjwfEtL5JVRD41MMDC6oh6KMm4LLAaKjqHVqe9j7Ydvs22QDA)\n",
        "\n",
        "### Step 3: Backpropagation update: $w_{jk} += \\Delta w_{jk}$, where:\n",
        "- $Œîw_{jk} = Œ±Œ¥_k^{(l)}a_j^{(l-1)}$\n",
        "  - $l$ is last layer: $Œ¥_k^{(l)} = [1-\\sigma(z_k^{(l)})]\\sigma(z_k^{(l)}) \\times (\\underbrace{y-\\hat{y}}_{y-a_k^{(l)}})$\n",
        "  - $l$ is not last layer: $Œ¥_k^{(l)} = [1-\\sigma(z_k^{(l)})]\\sigma(z_k^{(l)}) \\times w_{k1}^{(l+1)}Œ¥_k^{(l+1)}$\n",
        "\n",
        "|Variable name (step-by-step order)|Instance 1|\n",
        "|---|---|\n",
        "|$x_1$|1|\n",
        "|$x_2$|0\n",
        "|$a_1$|$œÉ(4) = 0.982$\n",
        "|$a_2$|$œÉ(9) = 0.999$\n",
        "|$\\hat{y} = \\sigma(z^\\text{(final layer)})$|0.8691\n",
        "|$y$|1\n",
        "|$E=0.5(y-\\hat{y})$|0.0086\n",
        "|$Œ¥^{(last)}$|0.8691 √ó (1‚àí0.8691) √ó (1-0.8691) = 0.0149\n",
        "|$Œ¥^{(last-1)}_1$|0.982 √ó (1‚àí0.982) √ó 6 √ó 0.0149 = 0.0016\n",
        "|$Œ¥^{(last-1)}_2$|0.999 √ó (1‚àí0.999) √ó (-6) √ó 0.0149 = 1.1e-6 $\\approx$ 0\n",
        "\n",
        "Here comes the update. Remember: $Œîw_{jk} = Œ±Œ¥_k^{(l)}a_j^{(l-1)}$\n",
        "\n",
        "|Variables|Update amount|New values|\n",
        "|---|---|---|\n",
        "$w_{0}$, $w_{1}$, $w_{2}$|0.7 √ó 0.0149 √ó (-1, 0.982, 0.999)|-2.01, 6.01,-5.99\n",
        "$w_{01}$, $w_{11}$, $w_{21}$|0.7 √ó 0.0016 √ó (-1, 1, 0)|1.9989, 6.0011, -6\n",
        "$w_{02}$, $w_{12}$, $w_{22}$|(0, 0, 0) (guess why?)| -1, 8, -8\n",
        "\n",
        "### Step 4: Rinse and repeat (with updated weights of course)!\n",
        "\n",
        "|Variable name (step-by-step order)|Instance 1: (1,0)| Instance 2: (0,1)| Instance 3: (1,1) | Instance 4: (0,0)|\n",
        "|---|---|---|---|---|\n",
        "|$x_1$|1|0|1|0\n",
        "|$x_2$|0|1|1|0\n",
        "|$a_1$|$œÉ(4) = 0.982$|$œÉ(-7.9989)$|$œÉ(-1.9978)$|$œÉ(-2.0086)$\n",
        "|$a_2$|$œÉ(9) = 0.999$|$œÉ(-7)$|$œÉ(0.9999)$|$œÉ(1.0181)$\n",
        "|$\\hat{y} = \\sigma(z^\\text{(final layer)})$|0.8691|0.8815|0.1622|0.1553\n",
        "|$y$|1|1|0|0\n",
        "|$E=0.5(y-\\hat{y})$|0.0086|0.007|0.0132|0.0121\n",
        "|$Œ¥^{(last)}$| 0.0149|0.0124|-0.0221|-0.0204\n",
        "|$Œ¥^{(last-1)}_1$|0.0016|0|-0.0139|-0.0128\n",
        "|$Œ¥^{(last-1)}_2$|0|0|0.0260|0.0238\n",
        "|$w_{0}$|-2.0103|-2.019| You do the rest!| I'm lazy\n",
        "|$w_{1}$|6.01|Same| If you're lazy too,| See solution pdf\n",
        "|$w_{2}$|-5.99|Same\n",
        "|$w_{01}$|1.9989|Same\n",
        "|$w_{11}$|6.0011|Same\n",
        "|$w_{21}$|-6|Same\n",
        "|$w_{02}$|-1|Same\n",
        "|$w_{12}$|8|Same\n",
        "|$w_{22}$|-8|Same"
      ],
      "metadata": {
        "id": "7f0dtv0k0nrY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<a href=\"https://imgflip.com/i/7z4jj7\"><img src=\"https://i.imgflip.com/7z4jj7.jpg\" title=\"made at imgflip.com\" height=300/></a><div><a href=\"https://imgflip.com/memegenerator\">Generated using Imgflip</a></div>\n",
        "\n",
        "## 3. Describe the mathematical formula of a multilayer perceptron with 1 hidden layer. Assume the input size is 1000, the hidden layer size is 100, and the output size is 20. Identify the parameters of the model, and their size.  \n",
        "\n",
        "Function: $g(x) = ùëì_2[ùëì_1(ùë•.ùë§_1+ùëè_1).ùë§_2+ùëè_2]$\n",
        "- Input and weights\n",
        "  - $x ‚àà (1, 1000)$\n",
        "  - $ùë§_1 ‚àà (1000, 100)$\n",
        "  - $ùë§_2 ‚àà (100, 20)$\n",
        "- Bias term:\n",
        "  - $b_1 ‚àà (1, 100)$\n",
        "  - $b_2 ‚àà (1, 20)$\n",
        "- Activation functions:\n",
        "  - $ùëì_1$ is an activation function such as ReLU or tanh\n",
        "  - $ùëì_2$ is softmax"
      ],
      "metadata": {
        "id": "bWBuXV0MbLlV"
      }
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/tuankhoin/COMP30027-Practical-Solutions/blob/main/2023/Week%202.ipynb)"
      ],
      "metadata": {
        "id": "g8myiiSKfL0x"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uAZpPad82_sS",
        "outputId": "cfe5aa1d-af7c-44cd-cba3-7845949d0f02",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 64
        }
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<marquee style='width: 50%; color: white; font-size:35px;' scrollamount=20><b>WELCOME TO COMP30027!</b></marquee>\n"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "%%html\n",
        "<marquee style='width: 50%; color: white; font-size:35px;' scrollamount=20><b>WELCOME TO COMP30027!</b></marquee>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v9XD5xgZ2_sh"
      },
      "source": [
        "## Boring stuff\n",
        "- My full name is Tuan-Khoi Nguyen, and you can call me **Khoi**\n",
        "- Master of Engineering (Mechatronics) - Just started my final year\n",
        "- Email: `tuankhoi@unimelb.edu.au` || `tuankhoin@student.unimelb.edu.au`\n",
        "\n",
        "| If... | Email me | Email Hasti |\n",
        "|---|---|---|\n",
        "Questions on subject content | ✅ | ✅ |\n",
        "'HOmEwOrk aTe mY dOG' | | ✅ |\n",
        "'Gimme marks' | | ✅ |\n",
        "'My homie AFK / MIA' | | ✅ |\n",
        "Landscape/Astro photography | ✅ | |\n",
        "Hiking | ✅ | |\n",
        "Music jam sesh | ✅ | |\n",
        "Dank memes | ✅ | |\n",
        "\n",
        "## Facts\n",
        "- May swear during teaching (sorry in advance)\n",
        "- Know Vietnamese restaurants that are actually good in Melbourne"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### The University of Melbourne, School of Computing and Information Systems\n",
        "# COMP30027 Machine Learning, 2023 Semester 1\n",
        "\n",
        "# Week 2 - Terminologies & Introduction\n",
        "\n",
        "## About the subject\n",
        "- Teaches machine learning (duh): concepts & terminologies, basic ML models\n",
        "- Really useful for your job interviews\n",
        "- Founding basics of the current trendy stuffs: ChatGPT, Midjourney, etc.\n",
        "- **Warning: Not easy marks**\n"
      ],
      "metadata": {
        "id": "PGS0crSQofrK"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r4E1uH8NRsW8"
      },
      "source": [
        "---\n",
        "## Theoretical questions\n",
        "**Question**: The following 3 problems are given:\n",
        "1. Skin cancer screening test\n",
        "2. Building a system that guesses what the weather (temperature, precipitation, etc.) will be like tomorrow \n",
        "3. Predicting products that a customer would be interested in buying, based on other purchases that customer has previously made \n",
        "\n",
        "For each problem:\n",
        "1. Task identification: What are we trying to learn?\n",
        "2. Selecting data: What instances and attributes for our dataset?\n",
        "3. Model picking: What model type are we picking here?\n",
        "4. Generalisation: How easy it is to generalize to other cases (e.g. weather forecast in another city)?\n",
        "\n",
        "**Answer**: \n",
        "\n",
        "Let's try the first example of skin cancer test. We will go slowly.\n",
        "\n",
        "Q1\n",
        "<details>\n",
        "    <summary>What do you want to get out of it?</summary>\n",
        "    Is there cancer?\n",
        "</details>\n",
        "<details>\n",
        "    <summary>What is the type of answer to that</summary>\n",
        "    Yes/No -> Binary\n",
        "</details>\n",
        "\n",
        "Q2\n",
        "\n",
        "Knowledge: \n",
        ">An instance is a single exemplar from the data, consisting of a bundle of (possibly unknown) attribute values (feature values) [and in the case of supervised ML a class value].\n",
        "\n",
        ">An attribute is a single measurement of some aspect of an instance, for example, the frequency of some event related to this instance, or the label of some meaningful category.\n",
        "\n",
        ">Attributes are usually classified as either nominal (labels with no ordering), ordinal (labels with an ordering), or continuous (numbers, even if they perhaps aren’t continuous in the mathematical sense).\n",
        "\n",
        "<details>\n",
        "    <summary>Each instace represents a subject of interest. A dataset has multiple instances. What can be a possible instance for our problem?</summary>\n",
        "    Patients\n",
        "</details>\n",
        "<details>\n",
        "    <summary>Each instance has a number of attributes representing its properties and specs. What can be possible attributes for our problem?</summary>\n",
        "    blood test, images of the skin, reports, observed syndromes, etc.\n",
        "</details>\n",
        "\n",
        "Q3:\n",
        "\n",
        "Knowledge:\n",
        "\n",
        "> Supervised: start from **labelled instances** in a set of training dataset and use them to classify unknown instances in test dataset. \n",
        "\n",
        "> Unsupervised methods are not based on a set of labelled training data. There are ‘weakly unsupervised methods’ (where the class set is known, but the system does not have access to labelled training data), and ‘strongly unsupervised methods’ (where even the class set is unknown,and we don’t even know how many classes we have).\n",
        "\n",
        "<details>\n",
        "    <summary>What model do you think would be suitable, given Q1 answers?</summary>\n",
        "    Classificaiton, specifically binary classification. Has to be supervised of course\n",
        "</details>\n",
        "\n",
        "Q4:\n",
        "\n",
        "Questions like this are open-ended, but you will need to show that you have put enough thoughts and knowledge of the subject into it.\n",
        "\n",
        "<details>\n",
        "    <summary>Can you think of possible drawback for our problem case?</summary>\n",
        "    Bias (unaccounted attribues/lack of representative data), Variance (same charasteristics may still have different outcomes)\n",
        "</details>\n",
        "<details>\n",
        "    <summary>How likely do you think these problems will happen?</summary>\n",
        "    In medical, there are many factors surrounding a person -> Easy to encounter these problems\n",
        "</details>\n",
        "\n",
        "Let's give it another try with the other 2 problems\n",
        "\n",
        "### Problem 2: Weather forecasting\n",
        "Q1\n",
        "<details>\n",
        "    <summary>What is the type of answer you want to get?</summary>\n",
        "    A number (temperature), or a category (rain/sun)\n",
        "</details>\n",
        "\n",
        "Q2\n",
        "<details>\n",
        "    <summary>What can be a possible instance for our problem?</summary>\n",
        "    A day (remember, we want to predict a day!)\n",
        "</details>\n",
        "<details>\n",
        "    <summary>What can be possible attributes for our problem?</summary>\n",
        "    temp, geographical information, etc.\n",
        "</details>\n",
        "\n",
        "Q3:\n",
        "<details>\n",
        "    <summary>What model do you think would be suitable, given Q1 answers?</summary>\n",
        "    Classificaiton for categories, or regression for numericals. Better to be supervised (note that classification is strictly supervised. If not, it's called clustering)\n",
        "</details>\n",
        "\n",
        "Q4:\n",
        "<details>\n",
        "    <summary>Can you think of possible drawback for our problem case?</summary>\n",
        "    Also bias and variance\n",
        "</details>\n",
        "<details>\n",
        "    <summary>How likely do you think these problems will happen?</summary>\n",
        "    Places with similar hemisphere and heights might be similar as well, or somehow related (e.g Australia season is invereted comparing to the Northern Hemisphere). If the rules are known, the problems will less likely to happen. Oh, but variance is definitely high here in Melbourne. I don't trust the weather forecast here.\n",
        "</details>\n",
        "\n",
        "### Problem 3: Product Recommendation\n",
        "Q1\n",
        "<details>\n",
        "    <summary>What is the type of answer you want to get?</summary>\n",
        "    Somes examples: interested/not keen, favorite product category given customer info, etc. Can you think of more?\n",
        "</details>\n",
        "\n",
        "Q2\n",
        "<details>\n",
        "    <summary>What can be a possible instance for our problem?</summary>\n",
        "    Customer, product? -> Pairings of customers and products sounds good\n",
        "</details>\n",
        "<details>\n",
        "    <summary>What can be possible attributes for our problem?</summary>\n",
        "    Details from both customers and products (can also do a bit of aggregation - this is feature engineering)\n",
        "</details>\n",
        "\n",
        "Q3:\n",
        "<details>\n",
        "    <summary>What model do you think would be suitable, given Q1 answers?</summary>\n",
        "    Classificaiton (supervised) or clustering (unsupervised) or association rule finding (unsupervised)\n",
        "</details>\n",
        "\n",
        "Q4:\n",
        "<details>\n",
        "    <summary>Can you think of possible drawback for our problem case?</summary>\n",
        "    Not all society groups behave the same\n",
        "</details>\n",
        "<details>\n",
        "    <summary>How likely do you think these problems will happen?</summary>\n",
        "    Very likely, which makes the problem hard to generalise well!\n",
        "</details>\n",
        "\n",
        "**Question**: What kinds of assumptions might a machine learning model make when tackling the problems?\n",
        "\n",
        "<details>\n",
        "    <summary>Answer</summary>\n",
        "    You assume that the attributes that you included will correlate to your prediction. And by choosing a model, you assume how that correletion looks like (linear, convex, wavy sine?)\n",
        "<details>\n",
        "    <summary>Example on choosing models</summary>\n",
        "    If you use linear regression to predict income of a group vs. number of person in that group, you are assuming that all people have the same income.\n",
        "</details>\n",
        "<details>\n",
        "    <summary>Example on how something souinding unrelated may actually be related</summary>\n",
        "    How can being a karen related to being cancer you're asking? Well, most karens are boomers, and boomers is more likely to develop cancer, because they are old.\n",
        "</details>\n",
        "</details>\n",
        "\n",
        "---\n",
        "## Coding time!\n",
        "\n",
        "### What are we using?\n",
        "- Python 3.x\n",
        "- Jupyter Notebook\n",
        "\n",
        "Just so?\n",
        "- `numpy`\n",
        "- `pandas`\n",
        "- `matplotlib`\n",
        "- `scikit-learn`\n",
        "- `scipy`\n",
        "\n",
        "### Do you even Notebook?\n",
        "- `pip`/`apt-get`/`brew`\n",
        "- Anaconda\n",
        "- VSCode & friends\n",
        "- Google Colab\n",
        "- What else?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mWEqAx6sRsXC"
      },
      "source": [
        "\n",
        "#### Reading and Processing Data\n",
        "\n",
        "*This week's code is deliberately written to be easy to understand, minimizing the use of libraries, syntactic sugar etc. Some extra alternative shortened answers were added along if you are interested.*\n",
        "\n",
        "In this workshop we are refreshing your knowledge about Python Series and DataFrames."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6XmTG-wSRsXD"
      },
      "outputs": [],
      "source": [
        "# let's read the data into a list of lines\n",
        "data = open('weather_data.csv', 'r').readlines()\n",
        "\n",
        "# we know that the first line is the label, the rest of the lines actually contains data\n",
        "header = data[0]\n",
        "instances = data[1:]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MNC581W4RsXF",
        "outputId": "8049f35c-987b-495b-ff48-93ac80df5d9b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "outlook,temperature,humidity,windy,play\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# let's look at our labels\n",
        "print(header)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P30xtwSJRsXH"
      },
      "source": [
        "**Q1. What is our goal here?**\n",
        "\n",
        "*In this dataset the goal is learn based on different weather features of a day if it's a good day for playing outside or not. In another word, after processing these data we want to be able to decide if a given day (with given weather feature values) can be a good day for playing outside or not.*\n",
        "\n",
        "**Q2. What do these labels represent?**\n",
        "\n",
        "*Play or Not Play*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4_BIERwFRsXI",
        "outputId": "fc4f48a9-2a60-4c89-ae1f-f558dda48701"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['sunny,hot,high,FALSE,no\\n', 'sunny,hot,high,TRUE,no\\n', 'overc,hot,high,FALSE,yes\\n', 'rainy,mild,high,FALSE,yes\\n', 'rainy,cool,normal,FALSE,yes\\n', 'rainy,cool,normal,TRUE,no\\n', 'overc,cool,normal,TRUE,yes\\n', 'sunny,mild,high,FALSE,no\\n', 'sunny,cool,normal,FALSE,yes\\n', 'rainy,mild,normal,FALSE,yes\\n', 'sunny,mild,normal,TRUE,yes\\n', 'overc,mild,high,TRUE,yes\\n', 'overc,hot,normal,FALSE,yes\\n', 'rainy,mild,high,TRUE,no\\n']\n"
          ]
        }
      ],
      "source": [
        "# let's look at our data\n",
        "print(instances)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mLPefmJxRsXJ"
      },
      "source": [
        "Let's use the list of instances, and create from it a list of features (x), and a list of labels (y)\n",
        "```python\n",
        "# first, initialize the empty lists\n",
        "features = []\n",
        "labels = []\n",
        "\n",
        "# iterate over our instances:\n",
        "for instance in instances:\n",
        "    \n",
        "    instance = instance.strip() #remove all leading and trailing whitespace (i.e., the newline symbol '\\n')\n",
        "    instance = instance.split(\",\") # split each instance at each comma, into separate values\n",
        "    \n",
        "    inst_features = ...   # Fill here \n",
        "   \n",
        "    inst_label = ...    # Fill here \n",
        "    \n",
        "    # append this instance's to our global list of features / labels\n",
        "    features.append(inst_features)\n",
        "    labels.append(inst_label)\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9S8k7In_RsXK"
      },
      "outputs": [],
      "source": [
        "# first, initialize the empty lists\n",
        "features = []\n",
        "labels = []\n",
        "\n",
        "# iterate over our instances:\n",
        "for instance in instances:\n",
        "    \n",
        "    instance = instance.strip() #remove all leading and trailing whitespace (i.e., the newline symbol '\\n')\n",
        "    instance = instance.split(\",\") # split each instance at each comma, into separate values\n",
        "   \n",
        "    inst_features = instance[:-1] # store the first 4 fields as the instance's features\n",
        "    \n",
        "    \n",
        "    inst_label = instance[-1] # store the label as the last field \n",
        "    \n",
        "    # append this instance's to our global list of features / labels\n",
        "    features.append(inst_features)\n",
        "    labels.append(inst_label)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6P37ht-bRsXL"
      },
      "source": [
        "Let's look at what we got"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nnMAR9gDRsXM",
        "outputId": "02656b97-ac17-4d42-cf60-91c33ff77a53"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "all features: [['sunny', 'hot', 'high', 'FALSE'], ['sunny', 'hot', 'high', 'TRUE'], ['overc', 'hot', 'high', 'FALSE'], ['rainy', 'mild', 'high', 'FALSE'], ['rainy', 'cool', 'normal', 'FALSE'], ['rainy', 'cool', 'normal', 'TRUE'], ['overc', 'cool', 'normal', 'TRUE'], ['sunny', 'mild', 'high', 'FALSE'], ['sunny', 'cool', 'normal', 'FALSE'], ['rainy', 'mild', 'normal', 'FALSE'], ['sunny', 'mild', 'normal', 'TRUE'], ['overc', 'mild', 'high', 'TRUE'], ['overc', 'hot', 'normal', 'FALSE'], ['rainy', 'mild', 'high', 'TRUE']]\n",
            "\n",
            "all labels  : ['no', 'no', 'yes', 'yes', 'yes', 'no', 'yes', 'no', 'yes', 'yes', 'yes', 'yes', 'yes', 'no']\n",
            "\n",
            "features of first instance: ['sunny', 'hot', 'high', 'FALSE'] \n",
            "label of first instance: no\n"
          ]
        }
      ],
      "source": [
        "print(\"all features: {}\\n\".format(features))\n",
        "print(\"all labels  : {}\\n\".format(labels))\n",
        "\n",
        "# print features and label of 1st instance\n",
        "print(\"features of first instance:\", features[0],\"\\nlabel of first instance:\", labels[0])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mc69BKRHRsXO"
      },
      "source": [
        "Now, computers are much better at working with numbers than with strings. Let's write a function that maps each type of value to a unique number. We can do this by\n",
        "\n",
        "1. creating a set of all occuring values (a set by definition contains each value exactly once)\n",
        "2. map each value to its position in this list\n",
        "\n",
        "For example\n",
        "- our observed values are `v=[a,b,c,a,a,b,d]`\n",
        "- turning this into a set: `set(v)=[a,b,c,d]`\n",
        "- and turning each value into a number based on its set position: a=0, b=1, c=2, d=3\n",
        "\n",
        "```python\n",
        "def string_feature_to_numeric_feature(str_values):\n",
        "    str_value_set = list(set(str_values)) # create a set of all values in value_list\n",
        "    numeric_values = [] # initialize our new value list\n",
        "    \n",
        "    for str_value in str_values:\n",
        "        \n",
        "        num_value = ...    # Fill here \n",
        "        # (hint: find on google a function that returns an index of a value in an array)\n",
        "   \n",
        "        numeric_values.append(num_value) # append the numeric value to the new value list\n",
        "    \n",
        "    return numeric_values # return the new numeric values as an output of the function\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LciBfxNiRsXP"
      },
      "outputs": [],
      "source": [
        "# Original answer\n",
        "def string_feature_to_numeric_feature(str_values):\n",
        "    \n",
        "    str_value_set = list(set(str_values)) # create a set of all values in value_list\n",
        "    \n",
        "    numeric_values = [] # initialize our new value list\n",
        "    \n",
        "    for str_value in str_values:\n",
        "        num_value = str_value_set.index(str_value) # Python way of saying: 'give me the position of str_value in list value_set'\n",
        "        numeric_values.append(num_value) # append the numeric value to the new value list\n",
        "        \n",
        "    return numeric_values # return the new numeric values as an output of the function\n",
        "\n",
        "# Shorter answer\n",
        "def string_feature_to_numeric_feature(str_values):\n",
        "  return list(range(len(set(str_values))))\n",
        "\n",
        "# Another shorter answer\n",
        "def string_feature_to_numeric_feature(str_values):\n",
        "  [idx for idx,_ in enumerate(set(str_values))]\n",
        "\n",
        "# Same function, written in lambda syntax (func_name = lambda inputs: outputs)\n",
        "string_feature_to_numeric_feature = lambda str_values: [idx for idx,_ in enumerate(set(str_values))]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qtBxhiehRsXQ"
      },
      "source": [
        "Let's see if it works"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BJice00ORsXQ",
        "outputId": "651ebeaa-ab6a-4afe-cf9e-6f6141a23c04"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "string labels : ['no', 'no', 'yes', 'yes', 'yes', 'no', 'yes', 'no', 'yes', 'yes', 'yes', 'yes', 'yes', 'no']\n",
            "numeric labels: [0, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0]\n"
          ]
        }
      ],
      "source": [
        "numeric_labels = string_feature_to_numeric_feature(labels)\n",
        "\n",
        "print(\"string labels : {}\".format(labels))\n",
        "print(\"numeric labels: {}\".format(numeric_labels))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8ufFG9tsRsXR"
      },
      "source": [
        "Similary, we can iterate over all features (columns in our data matrix), and transform all our features and labels to numeric values\n",
        "\n",
        "```python\n",
        "# print the original features\n",
        "print(\"This is our original feature matrix:\")\n",
        "for i in features:\n",
        "    print('\\t'.join(i))\n",
        "\n",
        "# initialize our new structure to hold the numeric features\n",
        "numeric_features = [[] for i in features]\n",
        "\n",
        "# iterate over each feature (i.e., over the columns of our data set)\n",
        "for feature_idx in range(len(features[0])):\n",
        "    # Fill here \n",
        "    # extract all values for that feature (i.e,. write all values in the nth column into a list)\n",
        "    ...\n",
        "    # apply our function\n",
        "    ...\n",
        "    # write the new, numeric feature values into the numeric feature structure\n",
        "    ...\n",
        "    \n",
        "# print the new, numeric veatures\n",
        "print(\"\\n\\nThis is our new, numeric feature matrix:\")\n",
        "for i in numeric_features:\n",
        "    print('{}\\t{}\\t{}\\t{}'.format(i[0], i[1], i[2], i[3]))\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rmtsD7IQRsXS",
        "outputId": "d143b83e-c9c8-44ea-8349-7a8cacd23a59"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "This is our original feature matrix:\n",
            "sunny\thot\thigh\tFALSE\n",
            "sunny\thot\thigh\tTRUE\n",
            "overc\thot\thigh\tFALSE\n",
            "rainy\tmild\thigh\tFALSE\n",
            "rainy\tcool\tnormal\tFALSE\n",
            "rainy\tcool\tnormal\tTRUE\n",
            "overc\tcool\tnormal\tTRUE\n",
            "sunny\tmild\thigh\tFALSE\n",
            "sunny\tcool\tnormal\tFALSE\n",
            "rainy\tmild\tnormal\tFALSE\n",
            "sunny\tmild\tnormal\tTRUE\n",
            "overc\tmild\thigh\tTRUE\n",
            "overc\thot\tnormal\tFALSE\n",
            "rainy\tmild\thigh\tTRUE\n",
            "String feature values: ['sunny', 'sunny', 'overc', 'rainy', 'rainy', 'rainy', 'overc', 'sunny', 'sunny', 'rainy', 'sunny', 'overc', 'overc', 'rainy']\n",
            "String feature values: ['hot', 'hot', 'hot', 'mild', 'cool', 'cool', 'cool', 'mild', 'cool', 'mild', 'mild', 'mild', 'hot', 'mild']\n",
            "String feature values: ['high', 'high', 'high', 'high', 'normal', 'normal', 'normal', 'high', 'normal', 'normal', 'normal', 'high', 'normal', 'high']\n",
            "String feature values: ['FALSE', 'TRUE', 'FALSE', 'FALSE', 'FALSE', 'TRUE', 'TRUE', 'FALSE', 'FALSE', 'FALSE', 'TRUE', 'TRUE', 'FALSE', 'TRUE']\n",
            "\n",
            "\n",
            "This is our new, numeric feature matrix:\n",
            "0\t0\t1\t1\n",
            "0\t0\t1\t0\n",
            "1\t0\t1\t1\n",
            "2\t1\t1\t1\n",
            "2\t2\t0\t1\n",
            "2\t2\t0\t0\n",
            "1\t2\t0\t0\n",
            "0\t1\t1\t1\n",
            "0\t2\t0\t1\n",
            "2\t1\t0\t1\n",
            "0\t1\t0\t0\n",
            "1\t1\t1\t0\n",
            "1\t0\t0\t1\n",
            "2\t1\t1\t0\n"
          ]
        }
      ],
      "source": [
        "# print the original features\n",
        "print(\"This is our original feature matrix:\")\n",
        "for i in features:\n",
        "    print('\\t'.join(i))\n",
        "\n",
        "# initialize our new structure to hold the numeric features\n",
        "numeric_features = [[] for i in features]\n",
        "\n",
        "# iterate over each feature (i.e., over the columns of our data set)\n",
        "for feature_idx in range(len(features[0])):\n",
        "    \n",
        "    # extract all values for that feature (i.e,. write all values in the nth column into a list)\n",
        "    str_feat_values = [values[feature_idx] for values in features]\n",
        "        \n",
        "    # apply our function\n",
        "    num_feat_values = string_feature_to_numeric_feature(str_feat_values)\n",
        "    \n",
        "    # write the new, numeric feature values into the numeric feature structure\n",
        "    for idx, _ in enumerate(features):\n",
        "        numeric_features[idx].append(num_feat_values[idx])\n",
        "\n",
        "# print the new, numeric veatures\n",
        "print(\"\\n\\nThis is our new, numeric feature matrix:\")\n",
        "for i in numeric_features:\n",
        "    print('{}\\t{}\\t{}\\t{}'.format(*i)) # *i here unpacks i into separate variables for the function"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H-dQENDARsXT"
      },
      "source": [
        "## Opening and reading csv files with Python's Pandas library\n",
        "\n",
        "There are various useful libraries which allow you to handle data sets much more efficiently (even though everything they do you could implement yourself fairly easily, similarly to the code you see above). A commonly used one is called <b>Pandas</b>. Below is some Pandas example code.\n",
        "\n",
        "**Fact: If you don't know anything: Documentation, Google and Stack Overflow is your friend**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HmrgZBKlRsXT",
        "outputId": "b69bfb01-8acf-4b11-b662-425bd8cef8c7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  outlook temperature humidity  windy play\n",
            "0   sunny         hot     high  False   no\n",
            "1   sunny         hot     high   True   no\n",
            "2   overc         hot     high  False  yes\n",
            "3   rainy        mild     high  False  yes\n",
            "4   rainy        cool   normal  False  yes\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "\n",
        "data_p = pd.read_csv('weather_data.csv', sep=',')\n",
        "\n",
        "print(data_p.head())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TYYT9RE6RsXU",
        "outputId": "f8760285-80c0-402b-f242-5f51fea7e368"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0      no\n",
            "1      no\n",
            "2     yes\n",
            "3     yes\n",
            "4     yes\n",
            "5      no\n",
            "6     yes\n",
            "7      no\n",
            "8     yes\n",
            "9     yes\n",
            "10    yes\n",
            "11    yes\n",
            "12    yes\n",
            "13     no\n",
            "Name: play, dtype: object\n"
          ]
        }
      ],
      "source": [
        "label_p = data_p['play']\n",
        "print(label_p)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wppChYG3RsXU",
        "outputId": "9d886536-ac04-437b-b2c9-c462d1d0c550"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   outlook temperature humidity  windy\n",
            "0    sunny         hot     high  False\n",
            "1    sunny         hot     high   True\n",
            "2    overc         hot     high  False\n",
            "3    rainy        mild     high  False\n",
            "4    rainy        cool   normal  False\n",
            "5    rainy        cool   normal   True\n",
            "6    overc        cool   normal   True\n",
            "7    sunny        mild     high  False\n",
            "8    sunny        cool   normal  False\n",
            "9    rainy        mild   normal  False\n",
            "10   sunny        mild   normal   True\n",
            "11   overc        mild     high   True\n",
            "12   overc         hot   normal  False\n",
            "13   rainy        mild     high   True\n"
          ]
        }
      ],
      "source": [
        "features_p = data_p[['outlook', 'temperature', 'humidity', 'windy']]\n",
        "print(features_p)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o1PBRdn3RsXV",
        "outputId": "92fde8ba-bb46-4dae-b7b9-b0c6b447e078"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "    outlook  temperature  humidity  windy\n",
            "0         0            0         0      0\n",
            "1         0            0         0      1\n",
            "2         1            0         0      0\n",
            "3         2            1         0      0\n",
            "4         2            2         1      0\n",
            "5         2            2         1      1\n",
            "6         1            2         1      1\n",
            "7         0            1         0      0\n",
            "8         0            2         1      0\n",
            "9         2            1         1      0\n",
            "10        0            1         1      1\n",
            "11        1            1         0      1\n",
            "12        1            0         1      0\n",
            "13        2            1         0      1\n",
            "[0 0 1 1 1 0 1 0 1 1 1 1 1 0]\n"
          ]
        }
      ],
      "source": [
        "# Turning string features into numeric features with minimal code. We use three handy tools:\n",
        "# 1 Pandas' 'apply' function which allows you to apply an operation to all items in the input dataframe\n",
        "# 2 Pandas' 'factorize' which automatically maps each categorical value to a unique integer\n",
        "#           it returns both the converted values, and the mapping it used. We are only interested in the converted\n",
        "#           values (hence the index [0])\n",
        "# 3 Python's lambda functionality 'lambda i: expression' which executes 'expression' any number of input arguments (here: colums)\n",
        "\n",
        "numeric_features_p = features_p.apply(lambda feature: pd.factorize(feature)[0])\n",
        "print(numeric_features_p)\n",
        "\n",
        "numeric_labels_p = pd.factorize(label_p)[0]\n",
        "print(numeric_labels_p)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gqy_g_a4RsXV"
      },
      "source": [
        "**After working through this tutorial you should know**\n",
        "\n",
        "- how to open and read in a data set from a csv file\n",
        "- how to split the data set into features (i.e., input to your ML algorithm) and labels (i.e., desired output of your ML algorithm)\n",
        "- how to map string values to numeric values\n",
        "- how to import and use a library (here: Pandas) in your Python program"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y45N-IwXRsXV",
        "outputId": "b6c1ce7a-5996-4dd6-9276-a02a7e53ed2a"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "\u001b[0;31mSignature:\u001b[0m\n",
              " \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfactorize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
              "\u001b[0;34m\u001b[0m    \u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
              "\u001b[0;34m\u001b[0m    \u001b[0msort\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'bool'\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
              "\u001b[0;34m\u001b[0m    \u001b[0mna_sentinel\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'int | None'\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
              "\u001b[0;34m\u001b[0m    \u001b[0msize_hint\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'int | None'\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
              "\u001b[0;34m\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;34m'tuple[np.ndarray, np.ndarray | Index]'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
              "\u001b[0;31mDocstring:\u001b[0m\n",
              "Encode the object as an enumerated type or categorical variable.\n",
              "\n",
              "This method is useful for obtaining a numeric representation of an\n",
              "array when all that matters is identifying distinct values. `factorize`\n",
              "is available as both a top-level function :func:`pandas.factorize`,\n",
              "and as a method :meth:`Series.factorize` and :meth:`Index.factorize`.\n",
              "\n",
              "Parameters\n",
              "----------\n",
              "values : sequence\n",
              "    A 1-D sequence. Sequences that aren't pandas objects are\n",
              "    coerced to ndarrays before factorization.\n",
              "sort : bool, default False\n",
              "    Sort `uniques` and shuffle `codes` to maintain the\n",
              "    relationship.\n",
              "\n",
              "na_sentinel : int or None, default -1\n",
              "    Value to mark \"not found\". If None, will not drop the NaN\n",
              "    from the uniques of the values.\n",
              "\n",
              "    .. versionchanged:: 1.1.2\n",
              "size_hint : int, optional\n",
              "    Hint to the hashtable sizer.\n",
              "\n",
              "Returns\n",
              "-------\n",
              "codes : ndarray\n",
              "    An integer ndarray that's an indexer into `uniques`.\n",
              "    ``uniques.take(codes)`` will have the same values as `values`.\n",
              "uniques : ndarray, Index, or Categorical\n",
              "    The unique valid values. When `values` is Categorical, `uniques`\n",
              "    is a Categorical. When `values` is some other pandas object, an\n",
              "    `Index` is returned. Otherwise, a 1-D ndarray is returned.\n",
              "\n",
              "    .. note::\n",
              "\n",
              "       Even if there's a missing value in `values`, `uniques` will\n",
              "       *not* contain an entry for it.\n",
              "\n",
              "See Also\n",
              "--------\n",
              "cut : Discretize continuous-valued array.\n",
              "unique : Find the unique value in an array.\n",
              "\n",
              "Notes\n",
              "-----\n",
              "Reference :ref:`the user guide <reshaping.factorize>` for more examples.\n",
              "\n",
              "Examples\n",
              "--------\n",
              "These examples all show factorize as a top-level method like\n",
              "``pd.factorize(values)``. The results are identical for methods like\n",
              ":meth:`Series.factorize`.\n",
              "\n",
              ">>> codes, uniques = pd.factorize(['b', 'b', 'a', 'c', 'b'])\n",
              ">>> codes\n",
              "array([0, 0, 1, 2, 0]...)\n",
              ">>> uniques\n",
              "array(['b', 'a', 'c'], dtype=object)\n",
              "\n",
              "With ``sort=True``, the `uniques` will be sorted, and `codes` will be\n",
              "shuffled so that the relationship is the maintained.\n",
              "\n",
              ">>> codes, uniques = pd.factorize(['b', 'b', 'a', 'c', 'b'], sort=True)\n",
              ">>> codes\n",
              "array([1, 1, 0, 2, 1]...)\n",
              ">>> uniques\n",
              "array(['a', 'b', 'c'], dtype=object)\n",
              "\n",
              "Missing values are indicated in `codes` with `na_sentinel`\n",
              "(``-1`` by default). Note that missing values are never\n",
              "included in `uniques`.\n",
              "\n",
              ">>> codes, uniques = pd.factorize(['b', None, 'a', 'c', 'b'])\n",
              ">>> codes\n",
              "array([ 0, -1,  1,  2,  0]...)\n",
              ">>> uniques\n",
              "array(['b', 'a', 'c'], dtype=object)\n",
              "\n",
              "Thus far, we've only factorized lists (which are internally coerced to\n",
              "NumPy arrays). When factorizing pandas objects, the type of `uniques`\n",
              "will differ. For Categoricals, a `Categorical` is returned.\n",
              "\n",
              ">>> cat = pd.Categorical(['a', 'a', 'c'], categories=['a', 'b', 'c'])\n",
              ">>> codes, uniques = pd.factorize(cat)\n",
              ">>> codes\n",
              "array([0, 0, 1]...)\n",
              ">>> uniques\n",
              "['a', 'c']\n",
              "Categories (3, object): ['a', 'b', 'c']\n",
              "\n",
              "Notice that ``'b'`` is in ``uniques.categories``, despite not being\n",
              "present in ``cat.values``.\n",
              "\n",
              "For all other pandas objects, an Index of the appropriate type is\n",
              "returned.\n",
              "\n",
              ">>> cat = pd.Series(['a', 'a', 'c'])\n",
              ">>> codes, uniques = pd.factorize(cat)\n",
              ">>> codes\n",
              "array([0, 0, 1]...)\n",
              ">>> uniques\n",
              "Index(['a', 'c'], dtype='object')\n",
              "\n",
              "If NaN is in the values, and we want to include NaN in the uniques of the\n",
              "values, it can be achieved by setting ``na_sentinel=None``.\n",
              "\n",
              ">>> values = np.array([1, 2, 1, np.nan])\n",
              ">>> codes, uniques = pd.factorize(values)  # default: na_sentinel=-1\n",
              ">>> codes\n",
              "array([ 0,  1,  0, -1])\n",
              ">>> uniques\n",
              "array([1., 2.])\n",
              "\n",
              ">>> codes, uniques = pd.factorize(values, na_sentinel=None)\n",
              ">>> codes\n",
              "array([0, 1, 0, 2])\n",
              ">>> uniques\n",
              "array([ 1.,  2., nan])\n",
              "\u001b[0;31mFile:\u001b[0m      ~/opt/anaconda3/lib/python3.9/site-packages/pandas/core/algorithms.py\n",
              "\u001b[0;31mType:\u001b[0m      function\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "? pd.factorize"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y3veSiEtRsXW"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.13"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}